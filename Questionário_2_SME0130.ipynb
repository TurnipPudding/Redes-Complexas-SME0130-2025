{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções Auxiliares e Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "file_path = \"C:/Users/gabri/Downloads/Redes Complexas/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo e plotando o grafo dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Hamsterster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de dados para a questão 1\n",
    "ham = nx.read_edgelist(file_path + \"data/hamsterster.txt\")\n",
    "\n",
    "# plt.figure(figsize=(12,10))\n",
    "# pos = nx.spring_layout(ham)\n",
    "# nx.draw(ham, pos, node_color=\"lightgray\", node_size=500, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base USairport500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de dados para a questão 2 e 4\n",
    "usa = nx.read_edgelist(file_path + \"data/USairport500.txt\")\n",
    "\n",
    "# plt.figure(figsize=(12,10))\n",
    "# pos = nx.spring_layout(usa)\n",
    "# nx.draw(usa, pos, node_color=\"lightgray\", node_size=50, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Advogato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de dados para a questão 3\n",
    "adv = nx.read_edgelist(file_path + \"data/advogato.txt\")\n",
    "\n",
    "# plt.figure(figsize=(12,10))\n",
    "# pos = nx.spring_layout(adv)\n",
    "# nx.draw(adv, pos, node_color=\"lightgray\", node_size=500, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Word_Adjacencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de dados para as questões 4 e 5\n",
    "word = nx.read_weighted_edgelist(file_path + \"data/word_adjacencies.txt\")\n",
    "\n",
    "# plt.figure(figsize=(12,10))\n",
    "# pos = nx.spring_layout(word)\n",
    "# nx.draw(word, pos, node_color=\"lightgray\", node_size=500, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização da Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que \"padroniza\" a rede, transformando-a em uma rede sem direção, e retornando o maior componente conectado para a análise.\n",
    "def padronizar_rede(G):\n",
    "    # Transformamos o grafo em uma rede sem direção.\n",
    "    G = G.to_undirected()\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "    # Vamos selecionar apenas o maior componente conectado.\n",
    "    Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "    G = G.subgraph(Gcc[0])\n",
    "\n",
    "    # Transformando os labels para números inteiros, começando com 0:\n",
    "\n",
    "    G = nx.convert_node_labels_to_integers(G, first_label=0)\n",
    "\n",
    "    # Número de vértices e arestas:\n",
    "\n",
    "    N = len(G)\n",
    "    M = G.number_of_edges()\n",
    "    print('Number of nodes:', N)\n",
    "    print('Number of edges:', M)\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções da Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo do Grau Médio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular o grau médio do grafo.\n",
    "def mean_degree(G):\n",
    "    vk = dict(G.degree()).values()\n",
    "    vk = np.array(list(vk))\n",
    "    print('Degree', vk)\n",
    "\n",
    "\n",
    "\n",
    "    md = np.mean(vk)\n",
    "    # print('Mean degree: ', md)\n",
    "    return md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da Distribuição do Grau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a distribuição do grau do grafo.\n",
    "def degree_distribution(G):\n",
    "    vk = dict(G.degree())\n",
    "    vk = list(vk.values())  # we get only the degree values\n",
    "    vk = np.array(vk)\n",
    "    maxk = np.max(vk)\n",
    "    mink = np.min(vk)\n",
    "    kvalues= np.arange(0,maxk+1) # possible values of k\n",
    "    Pk = np.zeros(maxk+1) # P(k)\n",
    "    for k in vk:\n",
    "        Pk[k] = Pk[k] + 1\n",
    "    Pk = Pk/sum(Pk) # the sum of the elements of P(k) must to be equal to one\n",
    "    return kvalues,Pk\n",
    "\n",
    "# Função para calcular o momento da distribuição do grau do grafo.\n",
    "def momment_of_degree_distribution(G,m):\n",
    "    k,Pk = degree_distribution(G)\n",
    "    M = sum((k**m)*Pk)\n",
    "    return M\n",
    "\n",
    "# Função para calcular a variância do grau.\n",
    "def variance(G):\n",
    "    variance = momment_of_degree_distribution(G,2) - momment_of_degree_distribution(G,1)**2\n",
    "    return variance\n",
    "# print(\"Variância do grau = \", variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo do Momento do Grau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular o momento do grafo.\n",
    "def momment(G,m):\n",
    "    M = 0\n",
    "    N = len(G)\n",
    "    for i in G.nodes:\n",
    "        M = M + G.degree(i)**m\n",
    "    M = M/N\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da Entropia de Shannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a entropia de Shannon do grafo.\n",
    "def shannon_entropy(G):\n",
    "    k,Pk = degree_distribution(G)\n",
    "    H = 0\n",
    "    for p in Pk:\n",
    "        if(p > 0):\n",
    "            H = H - p*np.math.log(p, 2)\n",
    "    return H\n",
    "\n",
    "# Função para calcular a entropia de Shannon normalizada do grafo.\n",
    "def normalized_shannon_entropy(G):\n",
    "    k,Pk = degree_distribution(G)\n",
    "    H = 0\n",
    "    for p in Pk:\n",
    "        if(p > 0):\n",
    "            H = H - p*np.math.log(p, 2)\n",
    "    return H/np.math.log(len(G),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da Transitividade e do Coeficiente de Agrupamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular o coeficiente de transitividade do grafo.\n",
    "def graph_transitivity(G):\n",
    "    CC = (nx.transitivity(G))\n",
    "    # print(\"Transitivity = \",\"%3.4f\"%CC)\n",
    "    return \"%3.4f\"%CC\n",
    "\n",
    "# Função para calcular o coeficiente de agrupamento do grafo.\n",
    "def avg_clustering_coefficient(G):\n",
    "    avc = nx.average_clustering(G)\n",
    "    # print(\"Average clustering:\", \"%3.4f\"%avc)\n",
    "    return \"%3.4f\"%avc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções da Questão 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular e plotar a distribuição de grau da rede.\n",
    "def distance(G):\n",
    "    if nx.is_connected(G) == True:\n",
    "        l = nx.average_shortest_path_length(G)\n",
    "        print(\"Average shortest path length:\", \"%3.4f\"%l)\n",
    "    else:\n",
    "        print(\"The graph has more than one connected component\")\n",
    "\n",
    "\n",
    "    N = len(G)\n",
    "    \n",
    "    d = nx.diameter(G)\n",
    "    print('Network diameter:', d)\n",
    "\n",
    "\n",
    "\n",
    "    E = nx.global_efficiency(G)\n",
    "    print('Network efficiency', E)\n",
    "\n",
    "    leff = nx.local_efficiency(G)\n",
    "    print('The average local efficiency of the network:', leff)\n",
    "\n",
    "\n",
    "\n",
    "    if nx.is_connected(G) == True:\n",
    "        D = np.zeros(shape=(N,N)) # D is the matrix of distances\n",
    "        vl = []\n",
    "        for i in np.arange(0,N):\n",
    "            for j in np.arange(i+1, N):\n",
    "                if(i != j):\n",
    "                    aux = nx.shortest_path(G,i,j)\n",
    "                    dij = len(aux)-1\n",
    "                    D[i][j] = dij\n",
    "                    D[j][i] = dij\n",
    "                    vl.append(dij)\n",
    "        x = range(0,d+1)\n",
    "        plt.hist(vl, bins = x, density=True, color='#0504aa',alpha=0.7, rwidth=0.85)\n",
    "        plt.title(\"Distribution of the geodesic distances\", fontsize=20)\n",
    "        plt.ylabel(\"P(l)\", fontsize=15)\n",
    "        plt.xlabel(\"Shortest path length (l)\", fontsize=15)\n",
    "        #plt.grid(True)\n",
    "        plt.savefig('av_short_path.svg')\n",
    "        plt.show(True)\n",
    "    else:\n",
    "        print(\"The graph has more than one connected component\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo da Correlação de Grau a Grau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular e plotar a correlação de grau a grau (degree-degree correlation).\n",
    "def degree_correlation(G):\n",
    "    r=nx.degree_assortativity_coefficient(G)\n",
    "    print(\"Assortativity = \",\"%3.4f\"%r)\n",
    "\n",
    "    ki = []\n",
    "    kj = []\n",
    "    for i in range(0,len(G.nodes())):\n",
    "        for j in range(0, len(G.nodes())):\n",
    "            if(G.has_edge(i,j) == True):\n",
    "                ki.append(G.degree(i))\n",
    "                kj.append(G.degree(j))\n",
    "                \n",
    "    from scipy.stats import pearsonr\n",
    "    # calculate Pearson's correlation\n",
    "    corr, _ = pearsonr(ki, kj)\n",
    "    print('Pearsons correlation: %.3f' % corr)\n",
    "\n",
    "\n",
    "\n",
    "    knn = []\n",
    "    for i in G.nodes():\n",
    "        aux =  nx.average_neighbor_degree(G, nodes = [i])\n",
    "        knn.append(float(aux[i]))\n",
    "    knn = np.array(knn)\n",
    "    print(\"Average degree of the neighborhood of the network:\", \"%3.2f\"%np.mean(knn))\n",
    "\n",
    "\n",
    "\n",
    "    vk = dict(G.degree())\n",
    "    vk = list(vk.values())\n",
    "\n",
    "\n",
    "\n",
    "    knnk = list()\n",
    "    ks = list()\n",
    "    for k in np.arange(np.min(vk), np.max(vk)+1):\n",
    "        aux = vk == k\n",
    "        if(len(knn[aux]) > 0):\n",
    "            av_knn = np.mean(knn[aux]) #average clustering among all the nodes with degree k\n",
    "            knnk.append(av_knn)\n",
    "            ks.append(k)\n",
    "    fig= plt.figure(figsize=(10,6))\n",
    "\n",
    "    plt.plot(ks, knnk, '-o', color='gray',markersize=10, linewidth=0,\n",
    "            markerfacecolor='lightgray',\n",
    "            markeredgecolor='black',\n",
    "            markeredgewidth=2)\n",
    "    #plt.loglog(ks,knnk,'bo',basex=10,basey=10)\n",
    "    #plt.title(\"Average neighborhood connectivity vs degree\")\n",
    "    plt.ylabel(\"knn(k)\", Fontsize = 20)\n",
    "    plt.xlabel(\"k\", Fontsize = 20)\n",
    "    #plt.savefig('knnk.eps')\n",
    "\n",
    "    # determine best fit line\n",
    "    par = np.polyfit(ks, knnk, 1, full=True)\n",
    "    slope=par[0][0]\n",
    "    intercept=par[0][1]\n",
    "    xl = [min(ks), max(ks)]\n",
    "    yl = [slope*xx + intercept  for xx in xl]\n",
    "    plt.plot(xl, yl, '--', linewidth=3, color='black')\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.savefig('knn.eps') #save the figure into a file\n",
    "    plt.show(True)\n",
    "\n",
    "\n",
    "\n",
    "    rho = np.corrcoef(ks, knnk)[0,1]\n",
    "    print('Pearson correlation coefficient:', rho)\n",
    "\n",
    "    from scipy import stats\n",
    "    s = stats.spearmanr(ks, knnk)\n",
    "    print('Spearman rank correlation coefficient:', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caminhadas Aleatórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as random\n",
    "\n",
    "edgelist=[(0,1),(1,2),(2,3), (3,1), (4,1), (4,5)]\n",
    "G = nx.Graph(edgelist)\n",
    "pos=nx.spring_layout(G)\n",
    "nx.draw(G, with_labels = True, node_size=500, font_size=16, pos = pos)\n",
    "plt.show(True)\n",
    "\n",
    "# random walk of length T\n",
    "T = 10\n",
    "seed_node = 0\n",
    "# neighbors\n",
    "ng = G.neighbors(seed_node)\n",
    "walk = []\n",
    "for t in range(0,T):\n",
    "    next_node = random.choice(list(ng))\n",
    "    ng = G.neighbors(next_node)\n",
    "    walk.append(next_node)\n",
    "print('Walk:', walk)\n",
    "\n",
    "\n",
    "\n",
    "nx.draw(G, with_labels = True, node_size=500, font_size=16, pos = pos)\n",
    "plt.show(True)\n",
    "\n",
    "A = nx.to_numpy_matrix(G)\n",
    "print(A)\n",
    "print('Number of walks of length two:')\n",
    "print(A@A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1)\n",
    "\n",
    "Para a rede social Hamsterster, calcule a média dos menores caminhos e o diâmetro. Considere apenas o maior componente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2)\n",
    "\n",
    "Para a rede de aeroportos (base USairport500), calcule a média e variância do comprimento dos menores caminhos. Considere apenas o maior componente na rede."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3)\n",
    "\n",
    "Calcule o coeficiente de assortatividade para a rede Advogato. Considere apenas o maior componente. Considere o valor mais próximo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 4)\n",
    "\n",
    "Para a rede de aeroportos (USairport500), calcule a entropia de Shannon considerando o comprimento dos menores caminhos. Use o logaritmo na base 2 e considere apenas o maior componente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 5)\n",
    "\n",
    "Calcule o coeficiente de correlação de Pearson entre o grau médio dos vizinhos e o grau para a rede de palavras (word_adjacencies). Considere apenas o maior componente conectado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
